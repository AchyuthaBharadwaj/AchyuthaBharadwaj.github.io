---
layout: post
title: "Analysis of Proximal Policy Optimization algorithm"
date: 2018-03-16
tags: [Machine Learning, Reinforcement Learning, Python, OpenAI, Tensorflow]
image: "ppo/cover.jpg"
---

### Goals:
* Comparing the algorithm performance with other baseline techniques for OpenAI game environment
* Exploring performance based on input data preprocessing , using different Neural Network architectures & CPU vs GPU training
* Modifying different hyperparameters to analyze their impact on the overall performance of the algorithm

[link to repository](https://github.com/AchyuthaBharadwaj/PPO)

### Implementation:

* The model is developed using TensorFlow and input data is collected from OpenAI GYM's MS-PACMAN environment.
* Performance of different neural network architectures is explored:
"CNN vs LSTM - Reward function"
![]({{ site.url }}{{ site.baseurl }}/img/ppo/ppo-1.png)

* GPU based training was done using Google Collaboratory
* Reference : OpenAI GYM Baselines

### Output:
Different models based on the modified hyperparemeters, CPU training & GPU training. Performance comparison(rewards & loss function) plots.